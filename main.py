# ğŸ“ main.py â€” Jarvis backend (FastAPI + OpenAI Realtime API)
# Ğ¡Ğ¾Ğ²Ğ¼ĞµÑÑ‚Ğ¸Ğ¼Ğ¾ Ñ openai-python â‰¥ 1.1.0

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from openai import AsyncOpenAI
import os
from typing import Optional, List, Union, Literal

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ OpenAI async-ĞºĞ»Ğ¸ĞµĞ½Ñ‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ FastAPI app â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
app = FastAPI()

# CORS (Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ ÑÑƒĞ·Ğ¸Ñ‚ÑŒ allow_origins Ğ´Ğ¾ ÑĞ²Ğ¾ĞµĞ³Ğ¾ Ğ´Ğ¾Ğ¼ĞµĞ½Ğ°)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ĞœĞ¾Ğ´ĞµĞ»Ğ¸ Ğ´Ğ»Ñ Realtime API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class InputAudioTranscription(BaseModel):
    model: str = "gpt-4o-transcribe"
    language: Optional[str] = None
    prompt: str = ""

class TurnDetection(BaseModel):
    type: str = "server_vad"
    threshold: float = 0.5
    prefix_padding_ms: int = 300
    silence_duration_ms: int = 300
    create_response: bool = True

class NoiseReduction(BaseModel):
    type: str = "near_field"

class RealtimeSessionRequest(BaseModel):
    model: str = "gpt-4o-realtime-preview"
    modalities: List[str] = ["audio", "text"]
    instructions: str = "Ğ¢Ñ‹ Ñ€ÑƒÑÑĞºĞ¾ÑĞ·Ñ‹Ñ‡Ğ½Ñ‹Ğ¹ Ğ³Ğ¾Ğ»Ğ¾ÑĞ¾Ğ²Ğ¾Ğ¹ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰Ğ½Ğ¸Ğº Ğ¿Ğ¾ Ğ¸Ğ¼ĞµĞ½Ğ¸ Jarvis. ĞÑ‚Ğ²ĞµÑ‡Ğ°Ğ¹ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ. Ğ¢Ğ²Ğ¾Ğ¸ Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹ Ğ´Ğ¾Ğ»Ğ¶Ğ½Ñ‹ Ğ±Ñ‹Ñ‚ÑŒ ĞºÑ€Ğ°Ñ‚ĞºĞ¸Ğ¼Ğ¸ Ğ¸ Ğ¿Ğ¾Ğ»ĞµĞ·Ğ½Ñ‹Ğ¼Ğ¸."
    voice: str = "nova"
    input_audio_format: str = "pcm16"
    output_audio_format: str = "pcm16"
    input_audio_transcription: Optional[InputAudioTranscription] = InputAudioTranscription()
    turn_detection: Optional[TurnDetection] = TurnDetection()
    input_audio_noise_reduction: Optional[NoiseReduction] = NoiseReduction()
    temperature: float = 0.8
    max_response_output_tokens: Union[int, Literal["inf"]] = "inf"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Endpoint Ğ´Ğ»Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ ÑĞµÑÑĞ¸Ğ¸ Realtime â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.post("/create_session")
async def create_session(req: RealtimeSessionRequest):
    try:
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ ÑĞµÑÑĞ¸Ñ Ñ‡ĞµÑ€ĞµĞ· OpenAI API
        response = await client.realtime.sessions.create(
            model=req.model,
            modalities=req.modalities,
            instructions=req.instructions,
            voice=req.voice,
            input_audio_format=req.input_audio_format,
            output_audio_format=req.output_audio_format,
            input_audio_transcription=req.input_audio_transcription.dict(exclude_none=True) if req.input_audio_transcription else None,
            turn_detection=req.turn_detection.dict(exclude_none=True) if req.turn_detection else None,
            input_audio_noise_reduction=req.input_audio_noise_reduction.dict(exclude_none=True) if req.input_audio_noise_reduction else None,
            temperature=req.temperature,
            max_response_output_tokens=req.max_response_output_tokens
        )
        
        # Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµĞ¼ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ»Ñ ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğ°
        return {
            "sessionId": response.id,
            "clientSecret": response.client_secret.value,
            "expiresAt": response.client_secret.expires_at,
            "voice": response.voice
        }
        
    except Exception as e:
        print(f"âŒ Session creation error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Health-check â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.get("/")
async def root():
    return {"status": "Jarvis Realtime server running ğŸš€"}
