# ğŸ“ main.py â€” Jarvis Voice Assistant Backend

import os
import asyncio
import json
import base64
import io
import tempfile
import traceback
import uuid
import secrets
import time
from typing import Optional, List, Union

from fastapi import FastAPI, HTTPException, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
# Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ğ´Ğ»Ñ ÑÑ‚Ğ°Ñ‚Ğ¸ĞºĞ¸
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
import httpx
from openai import AsyncOpenAI

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
API_KEY = os.getenv("OPENAI_API_KEY")
if not API_KEY:
    raise ValueError("OPENAI_API_KEY not found in environment variables")

port = int(os.getenv("PORT", "10000"))
client = AsyncOpenAI(api_key=API_KEY)
app = FastAPI(title="Jarvis Voice Assistant API")

# Ğ¼Ğ¾Ğ½Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¿Ğ°Ğ¿ĞºÑƒ public ĞºĞ°Ğº ÑÑ‚Ğ°Ñ‚Ğ¸ĞºÑƒ (Ğ¾Ñ‚Ğ´Ğ°Ñ‘Ğ¼ index.html Ğ¿Ñ€Ğ¸ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞµ /)
app.mount("/", StaticFiles(directory="public", html=True), name="static")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Data Models â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class TTSRequest(BaseModel):
    text: str
    voice: str = "alloy"

class AudioTranscriptionRequest(BaseModel):
    audio: str

class ChatItem(BaseModel):
    role: str
    content: str

class ChatRequest(BaseModel):
    messages: List[ChatItem]
    system_prompt: Optional[str] = (
        "Ğ¢Ñ‹ Ñ€ÑƒÑÑĞºĞ¾ÑĞ·Ñ‹Ñ‡Ğ½Ñ‹Ğ¹ Ğ³Ğ¾Ğ»Ğ¾ÑĞ¾Ğ²Ğ¾Ğ¹ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰Ğ½Ğ¸Ğº Ğ¿Ğ¾ Ğ¸Ğ¼ĞµĞ½Ğ¸ Jarvis. ĞÑ‚Ğ²ĞµÑ‡Ğ°Ğ¹ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ. Ğ¢Ğ²Ğ¾Ğ¸ Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹ Ğ´Ğ¾Ğ»Ğ¶Ğ½Ñ‹ Ğ±Ñ‹Ñ‚ÑŒ ĞºÑ€Ğ°Ñ‚ĞºĞ¸Ğ¼Ğ¸ Ğ¸ Ğ¿Ğ¾Ğ»ĞµĞ·Ğ½Ñ‹Ğ¼Ğ¸."
    )
    temperature: Optional[float] = 0.7

# Realtime session request
class RealtimeSessionRequest(BaseModel):
    model: str = "gpt-4o-realtime-preview"
    modalities: List[str] = ["audio", "text"]
    instructions: str = (
        "Ğ¢Ñ‹ Ñ€ÑƒÑÑĞºĞ¾ÑĞ·Ñ‹Ñ‡Ğ½Ñ‹Ğ¹ Ğ³Ğ¾Ğ»Ğ¾ÑĞ¾Ğ²Ğ¾Ğ¹ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰Ğ½Ğ¸Ğº Ğ¿Ğ¾ Ğ¸Ğ¼ĞµĞ½Ğ¸ Jarvis. ĞÑ‚Ğ²ĞµÑ‡Ğ°Ğ¹ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ."
    )
    voice: str = "alloy"
    input_audio_format: str = "pcm16"
    output_audio_format: str = "pcm16"
    input_audio_transcription: Optional[dict] = None
    turn_detection: Optional[dict] = None
    input_audio_noise_reduction: Optional[dict] = None
    temperature: float = 0.8
    max_response_output_tokens: Union[int, str] = "inf"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Endpoints â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.post("/create_session")
async def create_session(req: RealtimeSessionRequest):
    session_id = str(uuid.uuid4())
    client_secret = secrets.token_hex(16)
    expires_at = int(time.time()) + 60
    return {
        "sessionId": session_id,
        "clientSecret": client_secret,
        "expiresAt": expires_at,
        "voice": req.voice
    }

@app.post("/transcribe")
async def transcribe_audio(request: AudioTranscriptionRequest):
    try:
        audio_data = base64.b64decode(request.audio)
        if len(audio_data) < 100:
            return {"transcript": "ĞÑƒĞ´Ğ¸Ğ¾ ÑĞ»Ğ¸ÑˆĞºĞ¾Ğ¼ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¾Ğµ Ğ¸Ğ»Ğ¸ Ğ¿ÑƒÑÑ‚Ğ¾Ğµ"}
        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as f:
            f.write(audio_data)
            fname = f.name
        with open(fname, 'rb') as audi:
            tr = await client.audio.transcriptions.create(
                model="whisper-1", file=audi, language="ru"
            )
        os.unlink(fname)
        text = tr.text or "ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ñ€Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ñ‚ÑŒ Ñ€ĞµÑ‡ÑŒ"
        return {"transcript": text}
    except Exception as e:
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

@app.websocket("/ws")
async def websocket_endpoint(ws: WebSocket):
    await ws.accept()
    ping = asyncio.create_task(ping_loop(ws))
    try:
        while True:
            data = await asyncio.wait_for(ws.receive_text(), timeout=60)
            msg = json.loads(data)
            # handle ping, messages, etc.
    except WebSocketDisconnect:
        pass
    finally:
        ping.cancel()

async def ping_loop(ws: WebSocket):
    try:
        while True:
            await asyncio.sleep(25)
            await ws.send_json({"type":"ping"})
    except asyncio.CancelledError:
        pass

@app.get("/")
```python
# ğŸ“ main.py â€” Jarvis Voice Assistant Backend

import os
import asyncio
import json
import base64
import io
import tempfile
import traceback
import uuid
import secrets
import time
from typing import Optional, List, Union

from fastapi import FastAPI, HTTPException, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
import httpx
from openai import AsyncOpenAI

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
API_KEY = os.getenv("OPENAI_API_KEY")
if not API_KEY:
    raise ValueError("OPENAI_API_KEY not found in environment variables")

port = int(os.getenv("PORT", "10000"))
client = AsyncOpenAI(api_key=API_KEY)
app = FastAPI(title="Jarvis Voice Assistant API")
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Data Models â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class TTSRequest(BaseModel):
    text: str
    voice: str = "alloy"

class AudioTranscriptionRequest(BaseModel):
    audio: str

class ChatItem(BaseModel):
    role: str
    content: str

class ChatRequest(BaseModel):
    messages: List[ChatItem]
    system_prompt: Optional[str] = (
        "Ğ¢Ñ‹ Ñ€ÑƒÑÑĞºĞ¾ÑĞ·Ñ‹Ñ‡Ğ½Ñ‹Ğ¹ Ğ³Ğ¾Ğ»Ğ¾ÑĞ¾Ğ²Ğ¾Ğ¹ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰Ğ½Ğ¸Ğº Ğ¿Ğ¾ Ğ¸Ğ¼ĞµĞ½Ğ¸ Jarvis. ĞÑ‚Ğ²ĞµÑ‡Ğ°Ğ¹ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ. Ğ¢Ğ²Ğ¾Ğ¸ Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹ Ğ´Ğ¾Ğ»Ğ¶Ğ½Ñ‹ Ğ±Ñ‹Ñ‚ÑŒ ĞºÑ€Ğ°Ñ‚ĞºĞ¸Ğ¼Ğ¸ Ğ¸ Ğ¿Ğ¾Ğ»ĞµĞ·Ğ½Ñ‹Ğ¼Ğ¸."
    )
    temperature: Optional[float] = 0.7

# Realtime session request
class RealtimeSessionRequest(BaseModel):
    model: str = "gpt-4o-realtime-preview"
    modalities: List[str] = ["audio", "text"]
    instructions: str = (
        "Ğ¢Ñ‹ Ñ€ÑƒÑÑĞºĞ¾ÑĞ·Ñ‹Ñ‡Ğ½Ñ‹Ğ¹ Ğ³Ğ¾Ğ»Ğ¾ÑĞ¾Ğ²Ğ¾Ğ¹ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰Ğ½Ğ¸Ğº Ğ¿Ğ¾ Ğ¸Ğ¼ĞµĞ½Ğ¸ Jarvis. ĞÑ‚Ğ²ĞµÑ‡Ğ°Ğ¹ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ."
    )
    voice: str = "alloy"
    input_audio_format: str = "pcm16"
    output_audio_format: str = "pcm16"
    input_audio_transcription: Optional[dict] = None
    turn_detection: Optional[dict] = None
    input_audio_noise_reduction: Optional[dict] = None
    temperature: float = 0.8
    max_response_output_tokens: Union[int, str] = "inf"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Endpoints â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.post("/create_session")
async def create_session(req: RealtimeSessionRequest):
    session_id = str(uuid.uuid4())
    client_secret = secrets.token_hex(16)
    expires_at = int(time.time()) + 60
    return {
        "sessionId": session_id,
        "clientSecret": client_secret,
        "expiresAt": expires_at,
        "voice": req.voice
    }

@app.post("/transcribe")
async def transcribe_audio(request: AudioTranscriptionRequest):
    try:
        audio_data = base64.b64decode(request.audio)
        if len(audio_data) < 100:
            return {"transcript": "ĞÑƒĞ´Ğ¸Ğ¾ ÑĞ»Ğ¸ÑˆĞºĞ¾Ğ¼ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¾Ğµ Ğ¸Ğ»Ğ¸ Ğ¿ÑƒÑÑ‚Ğ¾Ğµ"}
        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as f:
            f.write(audio_data)
            fname = f.name
        with open(fname, 'rb') as audi:
            tr = await client.audio.transcriptions.create(
                model="whisper-1", file=audi, language="ru"
            )
        os.unlink(fname)
        text = tr.text or "ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ñ€Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ñ‚ÑŒ Ñ€ĞµÑ‡ÑŒ"
        return {"transcript": text}
    except Exception as e:
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

@app.websocket("/ws")
async def websocket_endpoint(ws: WebSocket):
    await ws.accept()
    ping = asyncio.create_task(ping_loop(ws))
    try:
        while True:
            data = await asyncio.wait_for(ws.receive_text(), timeout=60)
            msg = json.loads(data)
            # handle ping, messages, etc.
    except WebSocketDisconnect:
        pass
    finally:
        ping.cancel()

async def ping_loop(ws: WebSocket):
    try:
        while True:
            await asyncio.sleep(25)
            await ws.send_json({"type":"ping"})
    except asyncio.CancelledError:
        pass

@app.get("/")
def root():
    return {"status":"running"}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=port)
